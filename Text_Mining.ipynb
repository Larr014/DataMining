{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuyEpZ5Cdy7L+rXoRhVWEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Larr014/DataMining/blob/master/Text_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjB31qrNj1Vi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "import nltk.corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AMQXsX0p-yp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "6be6120a-1a9b-4fdd-962d-c08c1cc23390"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BaBlc3ukH_Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7bd7aef5-7069-4f97-b025-20a1d80ee00e"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPy-1tKykNcn"
      },
      "source": [
        "#Tokenization\n",
        "text = \"Right-click on an element (or a blank area), and choose 'Inspect' or 'Inspect Element' to see what elements are made up of (you will see both the HTML and the CSS). You can also edit the HTML or CSS on-the-fly in the Elements or Styles panel that opens.\"\n",
        "from nltk.tokenize import word_tokenize\n",
        "def tokenization(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkUUoiLlk9Ow"
      },
      "source": [
        "#Frecuencia de una palabra\n",
        "from nltk.probability import FreqDist\n",
        "def tokenFrecuency(tokens):\n",
        "  fdist = FreqDist(tokens)\n",
        "  return fdist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE516TU9lPO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "f4d16f65-efbb-4bf1-b6ac-96f07e87f9f8"
      },
      "source": [
        "#Encontrar los 10 más frecuentes\n",
        "fdist1 = fdist.most_common(10)\n",
        "fdist1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('or', 4),\n",
              " ('the', 4),\n",
              " ('(', 2),\n",
              " (')', 2),\n",
              " ('and', 2),\n",
              " (\"'Inspect\", 2),\n",
              " (\"'\", 2),\n",
              " ('see', 2),\n",
              " ('HTML', 2),\n",
              " ('CSS', 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrAO3ILIoJQ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2be7a525-fdc2-487f-887a-d53bb1bf8d20"
      },
      "source": [
        "#Stop words\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "def stopWords(tokens):\n",
        "  a = set(stopwords.words(\"english\"))\n",
        "  text1 = [x.lower() for x in tokens]\n",
        "  sws = [x for x in text1 if x not in a]\n",
        "  return sws"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY2p90pVl5NQ"
      },
      "source": [
        "#Stemming Porter\n",
        "from nltk.stem import PorterStemmer\n",
        "def stemming(tokens):\n",
        "  text = []\n",
        "  for word in tokens:\n",
        "    text.append(pst.stem(word))\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJsfZuq7tebo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d0919fd7-a6f0-4765-bf81-31e77329bccb"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "def lemmatization(tokens):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text = []\n",
        "  for word in tokens:\n",
        "    text.append(lemmatizer.lemmatize(word))\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2PUxTm4uUS6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5a1ef60d-bd8c-48d2-f176-e7704d87bde0"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "def posTagging(tokens):\n",
        "  tags = nltk.pos_tag(tokens)\n",
        "  return tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCVT51r1u836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b0a82ec2-e6ee-4fd7-f0f6-29d26d7addeb"
      },
      "source": [
        "from nltk import ne_chunk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "def namedEntityRecognition(tags):\n",
        "  chunk = ne_chunk(tags)\n",
        "  return chunk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqzd3AzP3SHb"
      },
      "source": [
        "def chunking(tags):\n",
        "  reg = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "  a = nltk.RegexpParser(reg)\n",
        "  result = a.parse(tags)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKRpDDmUpYSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "da995b93-7abd-4d64-c6df-3af598804a54"
      },
      "source": [
        "path = \"/gdrive/My Drive/Colab Notebooks/dataset/text Mining/nlpEjercicio.txt\"\n",
        "file1 = open(path, \"r\")\n",
        "text = file1.read()\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.”'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWhPLS8eqgHg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0181750f-7127-4638-d64e-339ee50587af"
      },
      "source": [
        "textTokens = tokenization(text)\n",
        "textTokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'linguistics',\n",
              " ',',\n",
              " 'computer',\n",
              " 'science',\n",
              " ',',\n",
              " 'information',\n",
              " 'engineering',\n",
              " ',',\n",
              " 'and',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'concerned',\n",
              " 'with',\n",
              " 'the',\n",
              " 'interactions',\n",
              " 'between',\n",
              " 'computers',\n",
              " 'and',\n",
              " 'human',\n",
              " '(',\n",
              " 'natural',\n",
              " ')',\n",
              " 'languages',\n",
              " ',',\n",
              " 'in',\n",
              " 'particular',\n",
              " 'how',\n",
              " 'to',\n",
              " 'program',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'process',\n",
              " 'and',\n",
              " 'analyze',\n",
              " 'large',\n",
              " 'amounts',\n",
              " 'of',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'data',\n",
              " '.',\n",
              " 'Challenges',\n",
              " 'in',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'frequently',\n",
              " 'involve',\n",
              " 'speech',\n",
              " 'recognition',\n",
              " ',',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " ',',\n",
              " 'and',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'generation',\n",
              " '.',\n",
              " '”']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyWdK5D-qrRo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "22510f32-6051-4b11-84c6-5c966004be12"
      },
      "source": [
        "textFrecuency = tokenFrecuency(textTokens)\n",
        "textFrecuency"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'(': 2,\n",
              "          ')': 2,\n",
              "          ',': 6,\n",
              "          '.': 2,\n",
              "          'Challenges': 1,\n",
              "          'NLP': 1,\n",
              "          'Natural': 1,\n",
              "          'a': 1,\n",
              "          'amounts': 1,\n",
              "          'analyze': 1,\n",
              "          'and': 4,\n",
              "          'artificial': 1,\n",
              "          'between': 1,\n",
              "          'computer': 1,\n",
              "          'computers': 2,\n",
              "          'concerned': 1,\n",
              "          'data': 1,\n",
              "          'engineering': 1,\n",
              "          'frequently': 1,\n",
              "          'generation': 1,\n",
              "          'how': 1,\n",
              "          'human': 1,\n",
              "          'in': 2,\n",
              "          'information': 1,\n",
              "          'intelligence': 1,\n",
              "          'interactions': 1,\n",
              "          'involve': 1,\n",
              "          'is': 1,\n",
              "          'language': 5,\n",
              "          'languages': 1,\n",
              "          'large': 1,\n",
              "          'linguistics': 1,\n",
              "          'natural': 5,\n",
              "          'of': 2,\n",
              "          'particular': 1,\n",
              "          'process': 1,\n",
              "          'processing': 2,\n",
              "          'program': 1,\n",
              "          'recognition': 1,\n",
              "          'science': 1,\n",
              "          'speech': 1,\n",
              "          'subfield': 1,\n",
              "          'the': 1,\n",
              "          'to': 2,\n",
              "          'understanding': 1,\n",
              "          'with': 1,\n",
              "          '”': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K8kuEGVrbdj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a30c508d-3aeb-4931-ff3e-5b34c7da1097"
      },
      "source": [
        "textTokens1 = stopWords(textTokens)\n",
        "textTokens1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'nlp',\n",
              " ')',\n",
              " 'subfield',\n",
              " 'linguistics',\n",
              " ',',\n",
              " 'computer',\n",
              " 'science',\n",
              " ',',\n",
              " 'information',\n",
              " 'engineering',\n",
              " ',',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'concerned',\n",
              " 'interactions',\n",
              " 'computers',\n",
              " 'human',\n",
              " '(',\n",
              " 'natural',\n",
              " ')',\n",
              " 'languages',\n",
              " ',',\n",
              " 'particular',\n",
              " 'program',\n",
              " 'computers',\n",
              " 'process',\n",
              " 'analyze',\n",
              " 'large',\n",
              " 'amounts',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'data',\n",
              " '.',\n",
              " 'challenges',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'frequently',\n",
              " 'involve',\n",
              " 'speech',\n",
              " 'recognition',\n",
              " ',',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'understanding',\n",
              " ',',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'generation',\n",
              " '.',\n",
              " '”']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B8Pssq0tCUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49f7a995-9ca4-40eb-d8d5-a57d380d7a7f"
      },
      "source": [
        "textTokens1 = stemming(textTokens1)\n",
        "textTokens1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " '(',\n",
              " 'nlp',\n",
              " ')',\n",
              " 'subfield',\n",
              " 'linguist',\n",
              " ',',\n",
              " 'comput',\n",
              " 'scienc',\n",
              " ',',\n",
              " 'inform',\n",
              " 'engin',\n",
              " ',',\n",
              " 'artifici',\n",
              " 'intellig',\n",
              " 'concern',\n",
              " 'interact',\n",
              " 'comput',\n",
              " 'human',\n",
              " '(',\n",
              " 'natur',\n",
              " ')',\n",
              " 'languag',\n",
              " ',',\n",
              " 'particular',\n",
              " 'program',\n",
              " 'comput',\n",
              " 'process',\n",
              " 'analyz',\n",
              " 'larg',\n",
              " 'amount',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'data',\n",
              " '.',\n",
              " 'challeng',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " 'frequent',\n",
              " 'involv',\n",
              " 'speech',\n",
              " 'recognit',\n",
              " ',',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'understand',\n",
              " ',',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'gener',\n",
              " '.',\n",
              " '”']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j7_BJUstSo4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5c2749f-c67f-4cc2-fde0-73635e1b490c"
      },
      "source": [
        "#Lemmatization\n",
        "textTokens1 = lemmatization(textTokens1)\n",
        "textTokens1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " '(',\n",
              " 'nlp',\n",
              " ')',\n",
              " 'subfield',\n",
              " 'linguist',\n",
              " ',',\n",
              " 'comput',\n",
              " 'scienc',\n",
              " ',',\n",
              " 'inform',\n",
              " 'engin',\n",
              " ',',\n",
              " 'artifici',\n",
              " 'intellig',\n",
              " 'concern',\n",
              " 'interact',\n",
              " 'comput',\n",
              " 'human',\n",
              " '(',\n",
              " 'natur',\n",
              " ')',\n",
              " 'languag',\n",
              " ',',\n",
              " 'particular',\n",
              " 'program',\n",
              " 'comput',\n",
              " 'process',\n",
              " 'analyz',\n",
              " 'larg',\n",
              " 'amount',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'data',\n",
              " '.',\n",
              " 'challeng',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " 'frequent',\n",
              " 'involv',\n",
              " 'speech',\n",
              " 'recognit',\n",
              " ',',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'understand',\n",
              " ',',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'gener',\n",
              " '.',\n",
              " '”']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_fpMLvetVW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8f7e64b-3eeb-4ff2-98a1-428ba8d685f6"
      },
      "source": [
        "#POS Tagging\n",
        "tags = posTagging(textTokens)\n",
        "tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('processing', 'NN'),\n",
              " ('(', '('),\n",
              " ('NLP', 'NNP'),\n",
              " (')', ')'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('subfield', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('linguistics', 'NNS'),\n",
              " (',', ','),\n",
              " ('computer', 'NN'),\n",
              " ('science', 'NN'),\n",
              " (',', ','),\n",
              " ('information', 'NN'),\n",
              " ('engineering', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('artificial', 'JJ'),\n",
              " ('intelligence', 'NN'),\n",
              " ('concerned', 'VBN'),\n",
              " ('with', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('interactions', 'NNS'),\n",
              " ('between', 'IN'),\n",
              " ('computers', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('human', 'JJ'),\n",
              " ('(', '('),\n",
              " ('natural', 'JJ'),\n",
              " (')', ')'),\n",
              " ('languages', 'NNS'),\n",
              " (',', ','),\n",
              " ('in', 'IN'),\n",
              " ('particular', 'JJ'),\n",
              " ('how', 'WRB'),\n",
              " ('to', 'TO'),\n",
              " ('program', 'NN'),\n",
              " ('computers', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('process', 'VB'),\n",
              " ('and', 'CC'),\n",
              " ('analyze', 'VB'),\n",
              " ('large', 'JJ'),\n",
              " ('amounts', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('data', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Challenges', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('processing', 'NN'),\n",
              " ('frequently', 'RB'),\n",
              " ('involve', 'VBP'),\n",
              " ('speech', 'NN'),\n",
              " ('recognition', 'NN'),\n",
              " (',', ','),\n",
              " ('natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('understanding', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('generation', 'NN'),\n",
              " ('.', '.'),\n",
              " ('”', 'VB')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfTv2uLBtXRQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7872981e-f99c-4f7d-fbc5-6898967b454d"
      },
      "source": [
        "#Named entity recognition\n",
        "chunk = namedEntityRecognition(tags)\n",
        "print(chunk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  Natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  (/(\n",
            "  (ORGANIZATION NLP/NNP)\n",
            "  )/)\n",
            "  is/VBZ\n",
            "  a/DT\n",
            "  subfield/NN\n",
            "  of/IN\n",
            "  linguistics/NNS\n",
            "  ,/,\n",
            "  computer/NN\n",
            "  science/NN\n",
            "  ,/,\n",
            "  information/NN\n",
            "  engineering/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  artificial/JJ\n",
            "  intelligence/NN\n",
            "  concerned/VBN\n",
            "  with/IN\n",
            "  the/DT\n",
            "  interactions/NNS\n",
            "  between/IN\n",
            "  computers/NNS\n",
            "  and/CC\n",
            "  human/JJ\n",
            "  (/(\n",
            "  natural/JJ\n",
            "  )/)\n",
            "  languages/NNS\n",
            "  ,/,\n",
            "  in/IN\n",
            "  particular/JJ\n",
            "  how/WRB\n",
            "  to/TO\n",
            "  program/NN\n",
            "  computers/NNS\n",
            "  to/TO\n",
            "  process/VB\n",
            "  and/CC\n",
            "  analyze/VB\n",
            "  large/JJ\n",
            "  amounts/NNS\n",
            "  of/IN\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  data/NNS\n",
            "  ./.\n",
            "  Challenges/NNS\n",
            "  in/IN\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  frequently/RB\n",
            "  involve/VBP\n",
            "  speech/NN\n",
            "  recognition/NN\n",
            "  ,/,\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  understanding/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  generation/NN\n",
            "  ./.\n",
            "  ”/VB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr75qt9StaMB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "730ea9c7-3acc-4878-80bd-79c6d9ef72ca"
      },
      "source": [
        "#Chunking\n",
        "chunkingTags = chunking(tags)\n",
        "print(chunkingTags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP Natural/JJ language/NN)\n",
            "  (NP processing/NN)\n",
            "  (/(\n",
            "  NLP/NNP\n",
            "  )/)\n",
            "  is/VBZ\n",
            "  (NP a/DT subfield/NN)\n",
            "  of/IN\n",
            "  linguistics/NNS\n",
            "  ,/,\n",
            "  (NP computer/NN)\n",
            "  (NP science/NN)\n",
            "  ,/,\n",
            "  (NP information/NN)\n",
            "  (NP engineering/NN)\n",
            "  ,/,\n",
            "  and/CC\n",
            "  (NP artificial/JJ intelligence/NN)\n",
            "  concerned/VBN\n",
            "  with/IN\n",
            "  the/DT\n",
            "  interactions/NNS\n",
            "  between/IN\n",
            "  computers/NNS\n",
            "  and/CC\n",
            "  human/JJ\n",
            "  (/(\n",
            "  natural/JJ\n",
            "  )/)\n",
            "  languages/NNS\n",
            "  ,/,\n",
            "  in/IN\n",
            "  particular/JJ\n",
            "  how/WRB\n",
            "  to/TO\n",
            "  (NP program/NN)\n",
            "  computers/NNS\n",
            "  to/TO\n",
            "  process/VB\n",
            "  and/CC\n",
            "  analyze/VB\n",
            "  large/JJ\n",
            "  amounts/NNS\n",
            "  of/IN\n",
            "  (NP natural/JJ language/NN)\n",
            "  data/NNS\n",
            "  ./.\n",
            "  Challenges/NNS\n",
            "  in/IN\n",
            "  (NP natural/JJ language/NN)\n",
            "  (NP processing/NN)\n",
            "  frequently/RB\n",
            "  involve/VBP\n",
            "  (NP speech/NN)\n",
            "  (NP recognition/NN)\n",
            "  ,/,\n",
            "  (NP natural/JJ language/NN)\n",
            "  (NP understanding/NN)\n",
            "  ,/,\n",
            "  and/CC\n",
            "  (NP natural/JJ language/NN)\n",
            "  (NP generation/NN)\n",
            "  ./.\n",
            "  ”/VB)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}